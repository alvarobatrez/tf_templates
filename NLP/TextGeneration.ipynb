{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1deb39c2-8711-4916-beaf-a3eeea095df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bad39d6a-dcc7-4923-b0f8-0e3277140690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38860074-dce5-4025-af29-4a0fe69d1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GRU\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25bb03b-0b48-4731-87fc-b31ed85e6fee",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "127e0e0c-9b7a-4fd8-be53-32fb5ea0df62",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\alvar\\\\Documents\\\\tf_templates\\\\DATA\\\\Quijote.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c53a361-e7e2-409f-ba2d-e0d5acbae01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d62efddc-726c-4655-b743-13212b53f594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El ingenioso hidalgo don Quijote de la Mancha\n",
      "por Miguel de Cervantes Saavedra\n",
      "El ingenioso hidalgo don Quijote de la Mancha\n",
      "Tasa\n",
      "Testimonio de las erratas\n",
      "El Rey\n",
      "Al Duque de Béjar\n",
      "Prólogo\n",
      "Al libro de don Quijote de la Mancha\n",
      "Que trata de la condición y ejercicio del famoso hidalgo don Quijote de la Mancha\n",
      "Que trata de la primera salida que de su tierra hizo el ingenioso don Quijote\n",
      "Donde se cuenta la graciosa manera que tuvo don Quijote en armarse caballero\n",
      "De lo que le sucedió a nuestro caball\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e02ad5e-b945-462c-9eda-34c59abf75bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z', '¡', '«', '»', '¿', 'Á', 'É', 'Í', 'Ñ', 'Ó', 'Ú', 'à', 'á', 'é', 'í', 'ï', 'ñ', 'ó', 'ù', 'ú', 'ü', '—']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(vocab)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42adb2e9-5ca7-40f2-9644-202a84c567a1",
   "metadata": {},
   "source": [
    "## Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8b285f2-9c88-44b1-b327-a8c34ae687b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " \"'\": 4,\n",
       " '(': 5,\n",
       " ')': 6,\n",
       " ',': 7,\n",
       " '-': 8,\n",
       " '.': 9,\n",
       " '0': 10,\n",
       " '1': 11,\n",
       " '2': 12,\n",
       " '3': 13,\n",
       " '4': 14,\n",
       " '5': 15,\n",
       " '6': 16,\n",
       " '7': 17,\n",
       " ':': 18,\n",
       " ';': 19,\n",
       " '?': 20,\n",
       " 'A': 21,\n",
       " 'B': 22,\n",
       " 'C': 23,\n",
       " 'D': 24,\n",
       " 'E': 25,\n",
       " 'F': 26,\n",
       " 'G': 27,\n",
       " 'H': 28,\n",
       " 'I': 29,\n",
       " 'J': 30,\n",
       " 'L': 31,\n",
       " 'M': 32,\n",
       " 'N': 33,\n",
       " 'O': 34,\n",
       " 'P': 35,\n",
       " 'Q': 36,\n",
       " 'R': 37,\n",
       " 'S': 38,\n",
       " 'T': 39,\n",
       " 'U': 40,\n",
       " 'V': 41,\n",
       " 'W': 42,\n",
       " 'X': 43,\n",
       " 'Y': 44,\n",
       " 'Z': 45,\n",
       " ']': 46,\n",
       " 'a': 47,\n",
       " 'b': 48,\n",
       " 'c': 49,\n",
       " 'd': 50,\n",
       " 'e': 51,\n",
       " 'f': 52,\n",
       " 'g': 53,\n",
       " 'h': 54,\n",
       " 'i': 55,\n",
       " 'j': 56,\n",
       " 'l': 57,\n",
       " 'm': 58,\n",
       " 'n': 59,\n",
       " 'o': 60,\n",
       " 'p': 61,\n",
       " 'q': 62,\n",
       " 'r': 63,\n",
       " 's': 64,\n",
       " 't': 65,\n",
       " 'u': 66,\n",
       " 'v': 67,\n",
       " 'x': 68,\n",
       " 'y': 69,\n",
       " 'z': 70,\n",
       " '¡': 71,\n",
       " '«': 72,\n",
       " '»': 73,\n",
       " '¿': 74,\n",
       " 'Á': 75,\n",
       " 'É': 76,\n",
       " 'Í': 77,\n",
       " 'Ñ': 78,\n",
       " 'Ó': 79,\n",
       " 'Ú': 80,\n",
       " 'à': 81,\n",
       " 'á': 82,\n",
       " 'é': 83,\n",
       " 'í': 84,\n",
       " 'ï': 85,\n",
       " 'ñ': 86,\n",
       " 'ó': 87,\n",
       " 'ù': 88,\n",
       " 'ú': 89,\n",
       " 'ü': 90,\n",
       " '—': 91}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ind = {u:i for i, u in enumerate(vocab)}\n",
    "char_to_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb0e2a8d-c0db-4232-bf23-8eac4bc1dc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2',\n",
       "       '3', '4', '5', '6', '7', ':', ';', '?', 'A', 'B', 'C', 'D', 'E',\n",
       "       'F', 'G', 'H', 'I', 'J', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S',\n",
       "       'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ']', 'a', 'b', 'c', 'd', 'e',\n",
       "       'f', 'g', 'h', 'i', 'j', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's',\n",
       "       't', 'u', 'v', 'x', 'y', 'z', '¡', '«', '»', '¿', 'Á', 'É', 'Í',\n",
       "       'Ñ', 'Ó', 'Ú', 'à', 'á', 'é', 'í', 'ï', 'ñ', 'ó', 'ù', 'ú', 'ü',\n",
       "       '—'], dtype='<U1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char = np.array(vocab)\n",
    "ind_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40f7be9b-ea2c-4d03-974b-814bbc806347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25, 57,  1, ..., 26, 55, 59])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = np.array([char_to_ind[c] for c in text])\n",
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaa75f80-5aee-4b43-96f6-516560eb97e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El ingenioso hidalgo'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = text[:20]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fcc0821-7691-4870-b112-9d7a7711a8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25, 57,  1, 55, 59, 53, 51, 59, 55, 60, 64, 60,  1, 54, 55, 50, 47,\n",
       "       57, 53, 60])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a5499b-c8cf-49ed-8e49-4adafdd7288f",
   "metadata": {},
   "source": [
    "## Creating Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d903f6c2-ccac-40ad-80ad-266cc07814fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El ingenioso hidalgo don Quijote de la Mancha\n",
      "por Miguel de Cervantes Saavedra\n",
      "El ingenioso hidalgo don Quijote de la Mancha\n",
      "Tasa\n",
      "Testimonio de las erratas\n",
      "El Rey\n",
      "Al Duque de Béjar\n",
      "Prólogo\n",
      "Al libro de don Quijote de la Mancha\n",
      "Que trata de la condición y ejercicio del famoso hidalgo don Quijote de la Mancha\n",
      "Que trata de la primera salida que de su tierra hizo el ingenioso don Quijote\n",
      "Donde se cuenta la graciosa manera que tuvo don Quijote en armarse caballero\n",
      "De lo que le sucedió a nuestro caball\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3529648e-ebc2-45e8-9ce7-d79853d2e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = '— Yo me acuerdo haber leído que un caballero español, llamado Diego Pérez de Vargas, habiéndosele en una batalla roto la espada, desgajó '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfd60e17-f2bf-4e58-ad36-a66734400089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d7766ea-9fbf-4093-bcb8-a4cf3d2ca08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = '— Yo me acuerdo haber leído que un caballero español, llamado Diego Pérez de Vargas, habiéndosele en una batalla roto la espada, desgajó de una encina un pesado ramo o tronco, y con él hizo tales cosas aquel día, y machacó tantos moros, que le quedó por sobrenombre Machuca, y así él como sus decendientes se llamaron, desde aquel día en adelante, Vargas y Machuca. Hete dicho esto, porque de la primera encina o roble que se me depare pienso desgajar otro tronco tal y tan bueno como aquél, que me imagino y pienso hacer con él tales hazañas, que tú te tengas por bien afortunado de haber merecido venir a vellas y a ser testigo de cosas que apenas podrán ser creídas.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9378cc5-e784-4f85-80ce-d7a7de1e5142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "669"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6159d4-69f7-446a-837c-b75312a40369",
   "metadata": {},
   "source": [
    "## Training Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b2ac686-8c3c-4003-bfaf-bb666413f59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14964"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 140\n",
    "total_num_seq = len(text) // (seq_len + 1)\n",
    "total_num_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41f5f531-0c0f-487f-95fc-91ab330cff56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E\n",
      "l\n",
      " \n",
      "i\n",
      "n\n",
      "g\n",
      "e\n",
      "n\n",
      "i\n",
      "o\n",
      "s\n",
      "o\n",
      " \n",
      "h\n",
      "i\n",
      "d\n",
      "a\n",
      "l\n",
      "g\n",
      "o\n",
      " \n",
      "d\n",
      "o\n",
      "n\n",
      " \n",
      "Q\n",
      "u\n",
      "i\n",
      "j\n",
      "o\n",
      "t\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      " \n",
      "l\n",
      "a\n",
      " \n",
      "M\n",
      "a\n",
      "n\n",
      "c\n",
      "h\n",
      "a\n",
      "\n",
      "\n",
      "p\n",
      "o\n",
      "r\n",
      " \n",
      "M\n",
      "i\n",
      "g\n",
      "u\n",
      "e\n",
      "l\n",
      " \n",
      "d\n",
      "e\n",
      " \n",
      "C\n",
      "e\n",
      "r\n",
      "v\n",
      "a\n",
      "n\n",
      "t\n",
      "e\n",
      "s\n",
      " \n",
      "S\n",
      "a\n",
      "a\n",
      "v\n",
      "e\n",
      "d\n",
      "r\n",
      "a\n",
      "\n",
      "\n",
      "E\n",
      "l\n",
      " \n",
      "i\n",
      "n\n",
      "g\n",
      "e\n",
      "n\n",
      "i\n",
      "o\n",
      "s\n",
      "o\n",
      " \n",
      "h\n",
      "i\n",
      "d\n",
      "a\n",
      "l\n",
      "g\n",
      "o\n",
      " \n",
      "d\n",
      "o\n",
      "n\n",
      " \n",
      "Q\n",
      "u\n",
      "i\n",
      "j\n",
      "o\n",
      "t\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      " \n",
      "l\n",
      "a\n",
      " \n",
      "M\n",
      "a\n",
      "n\n",
      "c\n",
      "h\n",
      "a\n",
      "\n",
      "\n",
      "T\n",
      "a\n",
      "s\n",
      "a\n",
      "\n",
      "\n",
      "T\n",
      "e\n",
      "s\n",
      "t\n",
      "i\n",
      "m\n",
      "o\n",
      "n\n",
      "i\n",
      "o\n",
      " \n",
      "d\n",
      "e\n",
      " \n",
      "l\n",
      "a\n",
      "s\n",
      " \n",
      "e\n",
      "r\n",
      "r\n",
      "a\n",
      "t\n",
      "a\n",
      "s\n",
      "\n",
      "\n",
      "E\n",
      "l\n",
      " \n",
      "R\n",
      "e\n",
      "y\n",
      "\n",
      "\n",
      "A\n",
      "l\n",
      " \n",
      "D\n",
      "u\n",
      "q\n",
      "u\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      " \n",
      "B\n",
      "é\n",
      "j\n",
      "a\n",
      "r\n",
      "\n",
      "\n",
      "P\n",
      "r\n",
      "ó\n",
      "l\n",
      "o\n",
      "g\n",
      "o\n",
      "\n",
      "\n",
      "A\n",
      "l\n",
      " \n",
      "l\n",
      "i\n",
      "b\n",
      "r\n",
      "o\n",
      " \n",
      "d\n",
      "e\n",
      " \n",
      "d\n",
      "o\n",
      "n\n",
      " \n",
      "Q\n",
      "u\n",
      "i\n",
      "j\n",
      "o\n",
      "t\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      " \n",
      "l\n",
      "a\n",
      " \n",
      "M\n",
      "a\n",
      "n\n",
      "c\n",
      "h\n",
      "a\n",
      "\n",
      "\n",
      "Q\n",
      "u\n",
      "e\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "d\n",
      "e\n",
      " \n",
      "l\n",
      "a\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "d\n",
      "i\n",
      "c\n",
      "i\n",
      "ó\n",
      "n\n",
      " \n",
      "y\n",
      " \n",
      "e\n",
      "j\n",
      "e\n",
      "r\n",
      "c\n",
      "i\n",
      "c\n",
      "i\n",
      "o\n",
      " \n",
      "d\n",
      "e\n",
      "l\n",
      " \n",
      "f\n",
      "a\n",
      "m\n",
      "o\n",
      "s\n",
      "o\n",
      " \n",
      "h\n",
      "i\n",
      "d\n",
      "a\n",
      "l\n",
      "g\n",
      "o\n",
      " \n",
      "d\n",
      "o\n",
      "n\n",
      " \n",
      "Q\n",
      "u\n",
      "i\n",
      "j\n",
      "o\n",
      "t\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      " \n",
      "l\n",
      "a\n",
      " \n",
      "M\n",
      "a\n",
      "n\n",
      "c\n",
      "h\n",
      "a\n",
      "\n",
      "\n",
      "Q\n",
      "u\n",
      "e\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "d\n",
      "e\n",
      " \n",
      "l\n",
      "a\n",
      " \n",
      "p\n",
      "r\n",
      "i\n",
      "m\n",
      "e\n",
      "r\n",
      "a\n",
      " \n",
      "s\n",
      "a\n",
      "l\n",
      "i\n",
      "d\n",
      "a\n",
      " \n",
      "q\n",
      "u\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      " \n",
      "s\n",
      "u\n",
      " \n",
      "t\n",
      "i\n",
      "e\n",
      "r\n",
      "r\n",
      "a\n",
      " \n",
      "h\n",
      "i\n",
      "z\n",
      "o\n",
      " \n",
      "e\n",
      "l\n",
      " \n",
      "i\n",
      "n\n",
      "g\n",
      "e\n",
      "n\n",
      "i\n",
      "o\n",
      "s\n",
      "o\n",
      " \n",
      "d\n",
      "o\n",
      "n\n",
      " \n",
      "Q\n",
      "u\n",
      "i\n",
      "j\n",
      "o\n",
      "t\n",
      "e\n",
      "\n",
      "\n",
      "D\n",
      "o\n",
      "n\n",
      "d\n",
      "e\n",
      " \n",
      "s\n",
      "e\n",
      " \n",
      "c\n",
      "u\n",
      "e\n",
      "n\n",
      "t\n",
      "a\n",
      " \n",
      "l\n",
      "a\n",
      " \n",
      "g\n",
      "r\n",
      "a\n",
      "c\n",
      "i\n",
      "o\n",
      "s\n",
      "a\n",
      " \n",
      "m\n",
      "a\n",
      "n\n",
      "e\n",
      "r\n",
      "a\n",
      " \n",
      "q\n",
      "u\n",
      "e\n",
      " \n",
      "t\n",
      "u\n",
      "v\n",
      "o\n",
      " \n",
      "d\n",
      "o\n",
      "n\n",
      " \n",
      "Q\n",
      "u\n",
      "i\n",
      "j\n",
      "o\n",
      "t\n",
      "e\n",
      " \n",
      "e\n",
      "n\n",
      " \n",
      "a\n",
      "r\n",
      "m\n",
      "a\n",
      "r\n",
      "s\n",
      "e\n",
      " \n",
      "c\n",
      "a\n",
      "b\n",
      "a\n",
      "l\n",
      "l\n",
      "e\n",
      "r\n",
      "o\n",
      "\n",
      "\n",
      "D\n",
      "e\n",
      " \n",
      "l\n",
      "o\n",
      " \n",
      "q\n",
      "u\n",
      "e\n",
      " \n",
      "l\n",
      "e\n",
      " \n",
      "s\n",
      "u\n",
      "c\n",
      "e\n",
      "d\n",
      "i\n",
      "ó\n",
      " \n",
      "a\n",
      " \n",
      "n\n",
      "u\n",
      "e\n",
      "s\n",
      "t\n",
      "r\n",
      "o\n",
      " \n",
      "c\n",
      "a\n",
      "b\n",
      "a\n",
      "l\n",
      "l\n"
     ]
    }
   ],
   "source": [
    "# Create Training Sequences\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
    "\n",
    "for i in char_dataset.take(500):\n",
    "     print(ind_to_char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15b11b14-1e1a-4c80-b7a2-06f2fb22456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41e7497e-2502-4859-99f8-6f0fac7c7c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seq_targets(seq):\n",
    "    input_txt = seq[:-1]\n",
    "    target_txt = seq[1:]\n",
    "    return input_txt, target_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85e2b01e-37e9-4bd4-aa92-52d00e40983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(create_seq_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a672a5c-0c8c-4b73-86d6-57c9c291fdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25 57  1 55 59 53 51 59 55 60 64 60  1 54 55 50 47 57 53 60  1 50 60 59\n",
      "  1 36 66 55 56 60 65 51  1 50 51  1 57 47  1 32 47 59 49 54 47  0 61 60\n",
      " 63  1 32 55 53 66 51 57  1 50 51  1 23 51 63 67 47 59 65 51 64  1 38 47\n",
      " 47 67 51 50 63 47  0 25 57  1 55 59 53 51 59 55 60 64 60  1 54 55 50 47\n",
      " 57 53 60  1 50 60 59  1 36 66 55 56 60 65 51  1 50 51  1 57 47  1 32 47\n",
      " 59 49 54 47  0 39 47 64 47  0 39 51 64 65 55 58 60 59 55 60]\n",
      "El ingenioso hidalgo don Quijote de la Mancha\n",
      "por Miguel de Cervantes Saavedra\n",
      "El ingenioso hidalgo don Quijote de la Mancha\n",
      "Tasa\n",
      "Testimonio\n",
      "\n",
      "\n",
      "[57  1 55 59 53 51 59 55 60 64 60  1 54 55 50 47 57 53 60  1 50 60 59  1\n",
      " 36 66 55 56 60 65 51  1 50 51  1 57 47  1 32 47 59 49 54 47  0 61 60 63\n",
      "  1 32 55 53 66 51 57  1 50 51  1 23 51 63 67 47 59 65 51 64  1 38 47 47\n",
      " 67 51 50 63 47  0 25 57  1 55 59 53 51 59 55 60 64 60  1 54 55 50 47 57\n",
      " 53 60  1 50 60 59  1 36 66 55 56 60 65 51  1 50 51  1 57 47  1 32 47 59\n",
      " 49 54 47  0 39 47 64 47  0 39 51 64 65 55 58 60 59 55 60  1]\n",
      "l ingenioso hidalgo don Quijote de la Mancha\n",
      "por Miguel de Cervantes Saavedra\n",
      "El ingenioso hidalgo don Quijote de la Mancha\n",
      "Tasa\n",
      "Testimonio \n"
     ]
    }
   ],
   "source": [
    "for input_txt, target_txt in  dataset.take(1):\n",
    "    print(input_txt.numpy())\n",
    "    print(''.join(ind_to_char[input_txt.numpy()]))\n",
    "    print('\\n')\n",
    "    print(target_txt.numpy())\n",
    "    # There is an extra whitespace!\n",
    "    print(''.join(ind_to_char[target_txt.numpy()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c8dca2-2aa0-4eb7-8305-ac78590cef9e",
   "metadata": {},
   "source": [
    "## Generating Training Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbc41448-2010-4cae-a945-4b6ed82ea268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "batch_size = 128\n",
    "\n",
    "# Buffer size to shuffle the dataset so it doesn't attempt to shuffle\n",
    "# the entire sequence in memory. Instead, it maintains a buffer in which it shuffles elements\n",
    "buffer_size = 10000\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5b70e7-db72-4900-b4aa-4f895cb072bb",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f86522f-3375-4d56-b6f9-c3a3fc58a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embed_dim = 10\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_neurons = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ef7a14e-3868-463b-959d-544e262663eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_cat_loss(y_true,y_pred):\n",
    "  return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31322742-7433-4231-9eae-74d9ac60d76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, embed_dim, rnn_neurons, weights=None):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embed_dim, weights=None))\n",
    "    model.add(GRU(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
    "    # Final Dense Layer to Predict\n",
    "    model.add(Dense(vocab_size))\n",
    "    model.compile(optimizer='adam', loss=sparse_cat_loss) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "340d19d3-d85e-4ca0-9b55-c465e30ff782",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized keyword arguments passed to Embedding: {'weights': None}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m  \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m  \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m  \u001b[49m\u001b[43mrnn_neurons\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrnn_neurons\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m(vocab_size, embed_dim, rnn_neurons, weights)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m(vocab_size, embed_dim, rnn_neurons, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      2\u001b[0m     model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m----> 3\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(\u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[0;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(GRU(rnn_neurons,return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,stateful\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,recurrent_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglorot_uniform\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Final Dense Layer to Predict\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\tf_templates\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:89\u001b[0m, in \u001b[0;36mEmbedding.__init__\u001b[1;34m(self, input_dim, output_dim, embeddings_initializer, embeddings_regularizer, embeddings_constraint, mask_zero, lora_rank, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `input_length` is deprecated. Just remove it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     88\u001b[0m     )\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dim \u001b[38;5;241m=\u001b[39m input_dim\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim \u001b[38;5;241m=\u001b[39m output_dim\n",
      "File \u001b[1;32m~\\Documents\\tf_templates\\venv\\Lib\\site-packages\\keras\\src\\layers\\layer.py:263\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[1;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_shape_arg \u001b[38;5;241m=\u001b[39m input_shape_arg\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m--> 263\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    264\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m     )\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocast \u001b[38;5;241m=\u001b[39m autocast\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized keyword arguments passed to Embedding: {'weights': None}"
     ]
    }
   ],
   "source": [
    "model = create_model(\n",
    "  vocab_size = vocab_size,\n",
    "  embed_dim=embed_dim,\n",
    "  rnn_neurons=rnn_neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5899e1-ff71-4347-b1dd-2b66103f46a8",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f939072b-5ac9-4906-822a-55e4726a1c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "\n",
    "  # Predict off some random batch\n",
    "  example_batch_predictions = model(input_example_batch)\n",
    "\n",
    "  # Display the dimensions of the predictions\n",
    "  print(example_batch_predictions.shape, \" <=== (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506805f2-4ca4-46da-b329-542bfad2345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2fbf9d-764b-4720-b649-588eaa7e700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d83ed1f-ff21-43d1-b78c-e0bead9feebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff67542f-086a-4675-967d-0af76e7dcfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat to not be a lists of lists\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137f56dc-40a9-49ec-ae5d-f98b0fbe6b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c0d789-8ab0-4930-90a3-e1ed571a1075",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Given the input seq: \\n\")\n",
    "print(\"\".join(ind_to_char[input_example_batch[0]]))\n",
    "print('\\n')\n",
    "print(\"Next Char Predictions: \\n\")\n",
    "print(\"\".join(ind_to_char[sampled_indices ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7413011d-4d93-483e-bf54-bd0b6ef011e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77401070-c014-4644-a980-c3b1ae95524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dataset, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb4fb9e-7d21-4937-9c16-817d4bf82bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('C:\\\\Users\\\\alvar\\\\Documents\\\\tf_templates\\\\NLP\\\\quijote_model.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28f4608-1873-462a-8a0d-d3c7d4d39429",
   "metadata": {},
   "source": [
    "## Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e601bd70-7443-4872-8757-2832a463f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Currently our model only expects 128 sequences at a time. We can create a new model\n",
    "that only expects a batch_size=1. We can create a new model with this batch size, then\n",
    "load our saved models weights. Then call .build() on the model:'''\n",
    "\n",
    "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
    "\n",
    "model.load_weights('C:\\\\Users\\\\alvar\\\\Documents\\\\tf_templates\\\\NLP\\\\quijote_model.weights.h5')\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82187d1e-a1e5-4ff6-b539-0940ae6a07c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
