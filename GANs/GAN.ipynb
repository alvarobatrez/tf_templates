{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96f4ce3-ebb3-42da-add0-75e69d1f471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b01d95c-9a42-4eed-b521-5f160b46de41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, LeakyReLU, Reshape, Conv2DTranspose, Dropout, Conv2D, Flatten\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4654cce2-a742-41ec-97b1-9f54aa0ddc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a79fea5-472d-4df9-a60b-72fdd0c71236",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2222ba-e8ba-4cab-99cc-922d89abbe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743eff88-ad78-47b2-bc97-0b27b992763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[99], cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2b6cf0-076f-4d08-9172-f6cb2248856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfa8114-c2a0-46f7-beb4-da2e24677e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef536bff-fd32-48d5-979b-7a756b6be977",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ed0f36-e881-4a07-a625-c87266cc186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.min())\n",
    "print(X_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756d720e-3195-4ece-8245-3670ea30cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 60000\n",
    "batch_size = 128\n",
    "latent_dim = 100\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0849bb-9928-40f2-ad72-d563d5a7126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(buffer_size).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92430347-406e-49d4-8b0e-fde381cebe06",
   "metadata": {},
   "source": [
    "## Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a5c612-71ca-4e5e-8caa-ad14904fb475",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Sequential([\n",
    "    Input(shape=(latent_dim,)),\n",
    "    Dense(units=7*7*256,use_bias=False),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(0.2),\n",
    "    \n",
    "    Reshape((7,7,256)),\n",
    "    \n",
    "    Conv2DTranspose(128, (5,5), strides=1, padding='same', use_bias=False),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(0.2),\n",
    "\n",
    "    Conv2DTranspose(64, (5,5), strides=2, padding='same', use_bias=False),\n",
    "    BatchNormalization(),\n",
    "    LeakyReLU(),\n",
    "\n",
    "    Conv2DTranspose(1, (5,5), strides=2, padding='same', use_bias=False, activation='tanh')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94672b5-6979-4c94-8ba3-a1e53ee79f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Sequential([\n",
    "    Input(shape=(28,28,1)),\n",
    "    Conv2D(64, (5,5), strides=2, padding='same'),\n",
    "    LeakyReLU(0.2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv2D(128, (5,5), strides=2, padding='same'),\n",
    "    LeakyReLU(0.2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2420d32a-8c21-409c-bf55-0e3e7aed0fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(test_noise, training=False)\n",
    "print(f\"Generator output shape: {generated_image.shape}\")\n",
    "\n",
    "test_image = tf.random.normal([1, 28, 28, 1])\n",
    "decision = discriminator(test_image)\n",
    "print(f\"Discriminator output shape: {decision.shape}\")  # Must be (1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6df468-9b69-4b3a-98fb-0a98d478b577",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dbe50c-5850-44e7-b617-ec9a748dd1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "\n",
    "    return real_loss + fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a519af-4053-4b6d-a61a-234b47df5a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aaed4e-ff99-4b67-8e13-31ab53191e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = Adam(0.0001)\n",
    "discriminator_optimizer = Adam(0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c016addd-fba4-4f08-80ba-82560e73ffa7",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0b4371-13d4-473d-9652-e18ff555e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([batch_size, latent_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90bbf7c-b319-409b-8d16-6805e7e55061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, epoch, seed):\n",
    "    predictions = model(seed, training=False)\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i,:,:,0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1251c78-9cc2-451d-af91-c1cfe542ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for image_batch in train_dataset:\n",
    "        gen_loss, disc_loss = train_step(image_batch)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        generate_images(generator, epoch+1, seed=tf.random.normal([16, latent_dim]))\n",
    "        print(f'Epoch {epoch + 1}, Gen Loss: {gen_loss}, Disc Loss: {disc_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a8238e-231a-4aef-a4b5-6fcc73917a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
